# Langgraph4j Deep Researcher Application Configuration
server:
  port: 8080
  servlet:
    context-path: /
  tomcat:
    max-threads: 200
    max-connections: 8192

spring:
  application:
    name: langgraph4j-deep-researcher
  profiles:
    active: dev
  jackson:
    date-format: yyyy-MM-dd HH:mm:ss
    time-zone: GMT+8
    default-property-inclusion: non_null

# Deep Research Core Configuration
deep-research:
  # AI Model Configuration
  model:
    api-key: ${CHAT_MODEL_API_KEY:your-api-key}
    api-url: ${CHAT_MODEL_API_URL:https://api.openai.com/v1}
    model-name: ${CHAT_MODEL_MODEL_NAME:gpt-4o-mini}
    temperature: ${CHAT_MODEL_TEMPERATURE:0.1}
    max-tokens: ${CHAT_MODEL_MAX_TOKENS:4096}
    log-requests: ${CHAT_MODEL_LOG_REQUESTS:true}
    log-responses: ${CHAT_MODEL_LOG_RESPONSES:true}
  
  # Search Engine Configuration
  search:
    default-engine: ${SEARCH_DEFAULT_ENGINE:tavily}
    tavily:
      api-key: ${TAVILY_API_KEY:your-api-key}
      base-url: ${TAVILY_BASE_URL:https://api.tavily.com/}
      search-depth: ${TAVILY_SEARCH_DEPTH:advanced}
      include-answer: ${TAVILY_INCLUDE_ANSWER:false}
      include-raw-content: ${TAVILY_INCLUDE_RAW_CONTENT:true}
      timeout-seconds: ${TAVILY_TIMEOUT_SECONDS:30}
  
  # Research Flow Configuration
  flow:
    default-max-loops: ${RESEARCH_MAX_LOOPS:3}
    default-max-search-results: ${RESEARCH_MAX_SEARCH_RESULTS:3}
    default-fetch-full-page: ${RESEARCH_FETCH_FULL_PAGE:true}
    max-tokens-per-source: ${RESEARCH_MAX_TOKENS_PER_SOURCE:1000}
    chars-per-token: ${RESEARCH_CHARS_PER_TOKEN:4}

  # Prompt Configuration
  prompts:
    query-generator: |
      You are a professional research assistant responsible for generating high-quality search queries based on research topics.
      
      Current time: {currentDate}
      Research topic: {researchTopic}
      
      Please generate a precise search query for the following research topic:
      
      Requirements:
      1. The search query should accurately capture the core content of the research topic
      2. Consider the current time to ensure searching for the latest information
      3. The query should be specific enough to obtain relevant results
      4. Avoid queries that are too broad or too narrow
      
      Please output the search query directly without explanation.

# Logging Configuration
logging:
  level:
    io.github.imfangs.ai.deepresearch: DEBUG
    dev.langchain4j: INFO
    org.bsc.langgraph4j: INFO
    org.springframework.web: INFO
    org.springframework.security: INFO
  pattern:
    file: "%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level [%X{requestId}] %logger{36} - %msg%n"
    console: "%clr(%d{yyyy-MM-dd HH:mm:ss.SSS}){faint} %clr([%X{requestId}]){blue} %clr(%-5level){color} %clr(%logger{36}){cyan} %clr(-){faint} %msg%n"

---
# Development Environment Configuration
spring:
  config:
    activate:
      on-profile: dev

logging:
  level:
    root: INFO
    io.github.imfangs.ai.deepresearch: DEBUG

---
# Production Environment Configuration
spring:
  config:
    activate:
      on-profile: prod

logging:
  level:
    root: WARN
    io.github.imfangs.ai.deepresearch: INFO
  file:
    path: ./logs
